---
title: "btc_hmm"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("varhandle")
library(varhandle)

```

```{r}
snp = read.csv("snp500weekly.csv")
#btc$perc = (btc$close-btc$open)/btc$open*100
snp$perc = (snp$Close-snp$Open)/snp$Open*100
hist(snp$perc, breaks=200)

```

```{r}
t3 = function(x, mu, v, k){
  num = gamma((v+1)/2)
  den = k*sqrt(pi*v)*gamma(v/2)*(1+((x-mu)/k)^2/v)^((v+1)/2)
  return(num/den)
}
#x = seq(-10, 30, length=100)
#y = unlist(lapply(x, t3, mu=0, v=280, k=2))
#plot(x, y)
```


```{r}
dat = snp$perc
#dat = observations[1:1000]
btc_CV = validation_sets(dat, 1:length(dat), fracs=c(0.7,0.2,0.1), window=0.05)
dens = t3
nstates = 5
parlist = list(
  tpm=matrix(rep(1/nstates, nstates^2), ncol=nstates, byrow=T),
  mu = runif(nstates, -5, 5),
  v = rep(6, nstates),
  k = rep(10, nstates)
)
#specify the transformations between natural and working parameters
np2wp.fn = list(tpm=tpm.np2wp, v=exp.np2wp, k=exp.np2wp)
wp2np.fn = list(tpm=tpm.wp2np, v=exp.wp2np, k=exp.wp2np)
mean.fn = function(mu, ...){return(mu)}
var.fn = function(k, v, ...){return(k^2*v/(v-2))}
cv.mse = 0
cv.0 = 0
for (i in 1:btc_CV$nsteps){
  train.ind = btc_CV$sets[[i]]$train_window
  val.ind = btc_CV$sets[[i]]$val_window
  train.set = dat[train.ind]
  val.set = dat[val.ind]
  
  hmm = hmm.fit(train.set, parlist, np2wp.fn, wp2np.fn, mean.fn, var.fn, dens)
  print(hmm)
  
  train.forecast = hmm.forecast(train.set, 1, hmm)
  y.hat.train = train.forecast$y.hat
  delta = train.forecast$delta
  #need to shift the predictions and actual so the indices match
  y.hat.train = y.hat.train[1:(length(y.hat.train)-1)]
  y.actual.train = train.set[2:length(train.set)]
  train.mse = mean((y.hat.train-y.actual.train)^2)
  train.0 = mean((y.actual.train-0)^2)
  
  val.forecast = hmm.forecast(val.set, 1, hmm, delta.curr=delta)
  y.hat.val = val.forecast$y.hat
  y.hat.val = y.hat.val[1:(length(y.hat.val)-1)]
  y.actual.val= val.set[2:length(val.set)]
  val.mse = mean((y.hat.val-y.actual.val)^2)
  val.0 = mean((y.actual.val-0)^2)
  cv.mse = cv.mse + val.mse
  cv.0 = cv.0 + val.0
  
  print((paste("Fold", i)))
  print(paste("train mse:", train.mse))
  print(paste("train mse rand:", train.0))
  print(paste("val mse:", val.mse))
  print(paste("val mse rand:", val.0))
  
  #store parlist for next iteration to use as new first guess
  parlist=list(
  tpm=hmm$tpm,
  mu=hmm$state.params$mu,
  v=hmm$state.params$v,
  k=hmm$state.params$k
)
}
print(paste("Final CV mse:", cv.mse/btc_CV$nsteps))
print(paste("Final CV mse just 0:", cv.0/btc_CV$nsteps))
```


```{r}
#2 states (t dist)
"Final CV mse: 2.34762934598386"
"Final CV mse just 0: 2.33161968345263"

#3 states (t dist)
"Final CV mse: 2.37948183452143"
"Final CV mse just 0: 2.33161968345263"

#4 states (t dist)
"Final CV mse: 2.29515086726578"
"Final CV mse just 0: 2.33161968345263"

#5 states (t dist)
"Final CV mse: 2.30859536973007"
"Final CV mse just 0: 2.33161968345263"



```






